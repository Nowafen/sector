#!/bin/bash

# Color Definitions
GREEN='\033[1;32m'
WHITE='\033[1;37m'
NC='\033[0m'
BOLD_RED='\033[1;31m'
BOLD_YELLOW='\033[1;33m'
BOLD_CYAN='\033[1;36m'
BOLD_GREEN='\033[1;32m'
BOLD_BLUE='\033[1;34m'
ORANGE='\033[0;33m'
BOLD_ORANGE='\033[1;33m'

# User-Agent
USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"

# Logo
display_logo() {
    echo -e "${WHITE}"
    echo "                   __
   ________  _____/ /_____  _____
  / ___/ _ \/ ___/ __/ __ \/ ___/
 (__  )  __/ /__/ /_/ /_/ / /    
/____/\___/\___/\__/\____/_/     
                by MNM           "
echo -e "${BOLD_YELLOW} An advanced tool for asset discovery${NC}"

}

# Help menu
display_help() {
    display_logo
    echo -e "${GREEN}
 Usage:${NC}"
    echo -e "${WHITE} sector [options]"
    echo -e "${GREEN}
Options:${NC}"
    echo -e "${WHITE}  -d {domain}     
             Specify a single target domain (e.g., example.com)"
    echo -e "${WHITE}  -l {file}       
             Specify a file containing a list of domains to scan (e.g., file-domains.txt)"
    echo -e "${WHITE}  -vhost {ip}     
             Specify an IP for virtual host scanning (e.g., http://5.5.5.5)"
    echo -e "${WHITE}  -nuclei         
             Smart scaning with private nuclei templates to find attack vectors"
    echo -e "${WHITE}  -h              
              Display this help menu"
    echo -e "${GREEN}
Examples:${NC}"
    echo -e "${WHITE}  sector.sh -d example.com"
    echo -e "${WHITE}  sector.sh -d example.com -vhost http://5.5.5.5"
    echo -e "${WHITE}  sector.sh -d example.com -nuclei"
    echo -e "${WHITE}  sector.sh -l file-domains.txt -nuclei"
    exit 0
}

# Check dependencies with customized checks
check_dependencies() {
    local tools=("subfinder" "assetfinder" "amass" "katana" "hakrawler" "waybackurls" "gf" "anew" "ffuf" "nuclei")
    local missing_tools=()

    # Check each tool with appropriate method
    for tool in "${tools[@]}"; do
        case $tool in
            hakrawler)
                if ! command -v "$tool" &>/dev/null || ! "$tool" --help &>/dev/null; then
                    missing_tools+=("$tool")
                fi
            ;;
            waybackurls)
                if ! command -v "$tool" &>/dev/null; then
                    missing_tools+=("$tool")
                fi
            ;;
            *)
                if ! "$tool" -h &>/dev/null; then
                    missing_tools+=("$tool")
                fi
            ;;
        esac
    done

    # Display warnings for missing tools
    if [[ ${#missing_tools[@]} -gt 0 ]]; then
        echo -e "${GREEN}Error: The following required tools are missing or not functioning:${NC}"
        for tool in "${missing_tools[@]}"; do
            echo -e "${WHITE}  - $tool${NC}"
        done
        echo -e "${GREEN}Please install the missing tools manually and ensure they are accessible in your PATH.${NC}"
        exit 1
    fi

    echo -e "${GREEN}All dependencies are installed and working. Starting sector...${NC}"
}

# Validate domain format
validate_domain() {
    local domain=$1
    if [[ "$domain" =~ ^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
        return 0
    else
        echo -e "${GREEN}Warning: Invalid domain format: $domain, skipping.${NC}"
        return 1
    fi
}

# Draw dynamic progress bar
draw_progress() {
    local width=$1
    local percent=$2
    local message=$3
    local bar_style=$4
    local filled=$((width * percent / 100))
    local empty=$((width - filled))
    local bar=""
    local fill_char
    case $bar_style in
        0) fill_char="=" ;;
        1) fill_char="-" ;;
        2) fill_char="~" ;;
        *) fill_char="=" ;;
    esac
    for ((i=0; i<filled; i++)); do bar+="$fill_char"; done
    [[ $filled -lt $width ]] && bar+=">"
    for ((i=0; i<empty; i++)); do bar+=" "; done
    printf "\r${GREEN}%s [%s] %d%%${NC}" "$message" "$bar" "$percent"
}

# Animate progress bar
animate_progress() {
    local message=$1
    local total_steps=$2
    local current_step=$3
    local pid=$4
    local bar_styles=("0" "1" "2")
    local bar_index=0
    while kill -0 "$pid" 2>/dev/null; do
        draw_progress 10 $((current_step * 100 / total_steps)) "$message" "${bar_styles[bar_index]}"
        ((bar_index=(bar_index+1)%3))
        sleep 0.8
    done
}

# Remove duplicate URLs based on unique parameter names and ensure all parameters are covered
remove_duplicate_urls() {
    local input_file=$1
    local output_file=$2
    if [[ ! -s "$input_file" ]]; then
        touch "$output_file"
        return
    fi

    # Create temporary files
    local temp_file=$(mktemp)
    local param_urls=$(mktemp)
    > "$temp_file"
    > "$param_urls"

    # Step 1: Extract all parameter names and their corresponding URLs
    declare -A param_to_urls
    while IFS= read -r url; do
        # Extract base URL and parameters
        base_url=$(echo "$url" | cut -d'?' -f1)
        params=$(echo "$url" | cut -d'?' -f2-)
        if [[ -z "$params" ]]; then
            echo "$url" >> "$temp_file"
            continue
        fi

        # Extract parameter names
        IFS='&' read -ra param_pairs <<< "$params"
        for param_pair in "${param_pairs[@]}"; do
            param_name=$(echo "$param_pair" | cut -d'=' -f1)
            if [[ -n "$param_name" ]]; then
                param_to_urls["$param_name"]+="$url\n"
            fi
        done
        echo "$url" >> "$param_urls"
    done < "$input_file"

    # Step 2: Identify all unique parameter names
    unique_params=("${!param_to_urls[@]}")
    total_params=${#unique_params[@]}
    [[ $total_params -eq 0 ]] && { sort -u "$temp_file" > "$output_file"; rm -f "$temp_file" "$param_urls"; return; }

    # Step 3: Greedy selection of URLs to cover all parameters
    declare -A covered_params
    selected_urls=()
    while [[ ${#covered_params[@]} -lt $total_params ]]; do
        best_url=""
        best_score=0
        best_new_params=()

        # Read URLs from param_urls
        while IFS= read -r url; do
            [[ -z "$url" ]] && continue
            # Skip already selected URLs
            [[ " ${selected_urls[*]} " =~ " $url " ]] && continue

            # Count new parameters this URL covers
            new_params=()
            IFS='&' read -ra param_pairs <<< "$(echo "$url" | cut -d'?' -f2-)"
            for param_pair in "${param_pairs[@]}"; do
                param_name=$(echo "$param_pair" | cut -d'=' -f1)
                if [[ -n "$param_name" && -z "${covered_params[$param_name]}" ]]; then
                    new_params+=("$param_name")
                fi
            done

            score=${#new_params[@]}
            if [[ $score -gt $best_score ]]; then
                best_url="$url"
                best_score=$score
                best_new_params=("${new_params[@]}")
            fi
        done < "$param_urls"

        # If no URL adds new parameters, break
        [[ -z "$best_url" ]] && break

        # Add the best URL and mark its parameters as covered
        selected_urls+=("$best_url")
        for param in "${best_new_params[@]}"; do
            covered_params["$param"]=1
        done
    done

    # Step 4: Write selected URLs to output
    for url in "${selected_urls[@]}"; do
        echo "$url" >> "$temp_file"
    done

    # Remove duplicates and write to output file
    sort -u "$temp_file" > "$output_file"
    rm -f "$temp_file" "$param_urls"
}

# Run Nuclei scan
run_nuclei_scan() {
    local output_dir=$1
    local subdomains_file=$2
    local xss_file="${output_dir}/gf/gf_xss.txt"
    local sqli_file="${output_dir}/gf/gf_sqli.txt"
    local nuclei_output="${output_dir}/nuclei_results.txt"
    local temp_output=$(mktemp)
    > "$nuclei_output"

    # Scan XSS vulnerabilities
    if [[ -s "$xss_file" ]]; then
        echo -e "${GREEN}Running Nuclei scan for XSS vulnerabilities...${NC}"
        stdbuf -oL nuclei -l "$xss_file" -tags xss -o "$temp_output" -silent -H "User-Agent: $USER_AGENT" 2>/dev/null
        if [[ -s "$temp_output" ]]; then
            echo -e "${BOLD_YELLOW}Nuclei XSS Alerts:${NC}"
            while IFS= read -r line; do
                template=$(echo "$line" | awk '{print $1}' | sed 's/\[\(.*\)\]/\1/')
                protocol=$(echo "$line" | awk '{print $2}' | sed 's/\[\(.*\)\]/\1/')
                severity=$(echo "$line" | awk '{print $3}' | sed 's/\[\(.*\)\]/\1/')
                url=$(echo "$line" | cut -d' ' -f4-)
                case $severity in
                    low) severity_color="${GREEN}" ;;
                    medium) severity_color="${ORANGE}" ;;
                    high) severity_color="${BOLD_ORANGE}" ;;
                    critical) severity_color="${BOLD_RED}" ;;
                    *) severity_color="${GREEN}" ;;
                esac
                echo -e "${WHITE}[${BOLD_GREEN}${template}${WHITE}] [${BOLD_BLUE}${protocol}${WHITE}] [${severity_color}${severity}${NC}] ${WHITE}${url}${NC}"
            done < "$temp_output"
            cat "$temp_output" >> "$nuclei_output"
            echo "" >> "$nuclei_output"
        fi
    else
        echo -e "${GREEN}Warning: XSS file $xss_file is empty or does not exist, skipping XSS scan.${NC}"
    fi

    # Scan SQLi vulnerabilities
    if [[ -s "$sqli_file" ]]; then
        echo -e "${GREEN}Running Nuclei scan for SQLi vulnerabilities...${NC}"
        stdbuf -oL nuclei -l "$sqli_file" -tags sqli,sqlinjection,blindsqli -o "$temp_output" -silent -H "User-Agent: $USER_AGENT" 2>/dev/null
        if [[ -s "$temp_output" ]]; then
            echo -e "${BOLD_RED}Nuclei SQLi Alerts:${NC}"
            while IFS= read -r line; do
                template=$(echo "$line" | awk '{print $1}' | sed 's/\[\(.*\)\]/\1/')
                protocol=$(echo "$line" | awk '{print $2}' | sed 's/\[\(.*\)\]/\1/')
                severity=$(echo "$line" | awk '{print $3}' | sed 's/\[\(.*\)\]/\1/')
                url=$(echo "$line" | cut -d' ' -f4-)
                case $severity in
                    low) severity_color="${GREEN}" ;;
                    medium) severity_color="${ORANGE}" ;;
                    high) severity_color="${BOLD_ORANGE}" ;;
                    critical) severity_color="${BOLD_RED}" ;;
                    *) severity_color="${GREEN}" ;;
                esac
                echo -e "${WHITE}[${BOLD_GREEN}${template}${WHITE}] [${BOLD_BLUE}${protocol}${WHITE}] [${severity_color}${severity}${NC}] ${WHITE}${url}${NC}"
            done < "$temp_output"
            cat "$temp_output" >> "$nuclei_output"
            echo "" >> "$nuclei_output"
        fi
    else
        echo -e "${GREEN}Warning: SQLi file $sqli_file is empty or does not exist, skipping SQLi scan.${NC}"
    fi

    # Scan subdomains with http/mnm/ template
    if [[ -s "$subdomains_file" ]]; then
        echo -e "${GREEN}Running Nuclei scan for subdomains with http/mnm/ template...${NC}"
        stdbuf -oL nuclei -l "$subdomains_file" -t http/mnm/ -o "$temp_output" -silent -H "User-Agent: $USER_AGENT" 2>/dev/null
        if [[ -s "$temp_output" ]]; then
            echo -e "${BOLD_CYAN}Nuclei Subdomains Alerts:${NC}"
            while IFS= read -r line; do
                template=$(echo "$line" | awk '{print $1}' | sed 's/\[\(.*\)\]/\1/')
                protocol=$(echo "$line" | awk '{print $2}' | sed 's/\[\(.*\)\]/\1/')
                severity=$(echo "$line" | awk '{print $3}' | sed 's/\[\(.*\)\]/\1/')
                url=$(echo "$line" | cut -d' ' -f4-)
                case $severity in
                    low) severity_color="${GREEN}" ;;
                    medium) severity_color="${ORANGE}" ;;
                    high) severity_color="${BOLD_ORANGE}" ;;
                    critical) severity_color="${BOLD_RED}" ;;
                    *) severity_color="${GREEN}" ;;
                esac
                echo -e "${WHITE}[${BOLD_GREEN}${template}${WHITE}] [${BOLD_BLUE}${protocol}${WHITE}] [${severity_color}${severity}${NC}] ${WHITE}${url}${NC}"
            done < "$temp_output"
            cat "$temp_output" >> "$nuclei_output"
            echo "" >> "$nuclei_output"
        fi
    else
        echo -e "${GREEN}Warning: Subdomains file $subdomains_file is empty or does not exist, skipping subdomains scan.${NC}"
    fi

    rm -f "$temp_output"
    echo -e "${GREEN}Nuclei scan completed, results saved to $nuclei_output${NC}"
}

# Process a single domain
process_domain() {
    local DOMAIN=$1
    local VHOST_IP=$2
    validate_domain "$DOMAIN" || return
    echo -e "${GREEN}Starting processing for domain: $DOMAIN${NC}"
    OUTPUT_DIR="recon_${DOMAIN}"
    GF_DIR="${OUTPUT_DIR}/gf"
    SUBDOMAINS_FILE="${OUTPUT_DIR}/subdomains"
    JS_URLS_FILE="${OUTPUT_DIR}/ALLjs.txt"
    VULNERABLE_FILE="${OUTPUT_DIR}/vulnerable.txt"
    NUCLEI_FILE="${OUTPUT_DIR}/nuclei_results.txt"

    if [[ -d "$OUTPUT_DIR" ]]; then
        echo -e "${GREEN}Warning: Directory $OUTPUT_DIR exists, skipping $DOMAIN.${NC}"
        return
    fi

    mkdir -p "$OUTPUT_DIR"
    mkdir -p "$GF_DIR"

    # Stage 1: Subdomain Enumeration
    total_steps=4
    [[ -n "$VHOST_IP" ]] && total_steps=5
    current_step=0
    message="Enumerating subdomains for $DOMAIN"
    stdbuf -oL subfinder -d "$DOMAIN" -all -silent > "${OUTPUT_DIR}/subfinder.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    stdbuf -oL assetfinder --subs-only "$DOMAIN" > "${OUTPUT_DIR}/assetfinder.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    stdbuf -oL amass enum -d "$DOMAIN" > "${OUTPUT_DIR}/amass.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    cat "${OUTPUT_DIR}"/*.txt 2>/dev/null | sort -u > "$SUBDOMAINS_FILE" 2>/dev/null
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0

    # If vhost is provided, perform virtual host scanning with ffuf
    if [[ -n "$VHOST_IP" ]]; then
        message="Performing virtual host scanning for $DOMAIN on $VHOST_IP"
        stdbuf -oL ffuf -w "$SUBDOMAINS_TXT" -u "$VHOST_IP/" -H "Host: FUZZ.$DOMAIN" -H "User-Agent: $USER_AGENT" -o "${OUTPUT_DIR}/vhost.txt" -silent 2>/dev/null &
        pid=$!
        animate_progress "$message" $total_steps $current_step $pid
        wait $pid
        ((current_step++))
        draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
        if [[ -s "${OUTPUT_DIR}/vhost.txt" ]]; then
            grep -oE "[a-zA-Z0-9.-]+\.$DOMAIN" "${OUTPUT_DIR}/vhost.txt" 2>/dev/null | sort -u >> "$SUBDOMAINS_FILE"
            cat "$SUBDOMAINS_FILE" | sort -u > "${OUTPUT_DIR}/temp_subdomains.txt"
            mv "${OUTPUT_DIR}/temp_subdomains.txt" "$SUBDOMAINS_FILE"
        fi
    fi

    subdomains_count=$(wc -l < "$SUBDOMAINS_FILE" 2>/dev/null || echo 0)
    rm -f "${OUTPUT_DIR}/subfinder.txt" "${OUTPUT_DIR}/assetfinder.txt" "${OUTPUT_DIR}/amass.txt" "${OUTPUT_DIR}/vhost.txt" "${OUTPUT_DIR}/temp_subdomains.txt" 2>/dev/null
    echo

    # Stage 2: JavaScript URL Extraction
    total_steps=4
    current_step=0
    message="Extracting JS URLs for $DOMAIN"
    stdbuf -oL cat "$SUBDOMAINS_FILE" 2>/dev/null | waybackurls 2>/dev/null | grep -iE "\.js$" > "${OUTPUT_DIR}/wayback_urls.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    stdbuf -oL cat "$SUBDOMAINS_FILE" 2>/dev/null | awk '{print "https://"$0}' | hakrawler -d 2 -t 8 -u "$USER_AGENT" 2>/dev/null | grep -iE "\.js$" > "${OUTPUT_DIR}/hakrawler_urls.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    stdbuf -oL katana -list "$SUBDOMAINS_FILE" -jc -H "User-Agent: $USER_AGENT" 2>/dev/null | grep -iE "\.js$" > "${OUTPUT_DIR}/katana_urls.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    cat "${OUTPUT_DIR}"/*_urls.txt 2>/dev/null | sort -u > "$JS_URLS_FILE" 2>/dev/null
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    js_urls_count=$(wc -l < "$JS_URLS_FILE" 2>/dev/null || echo 0)
    rm -f "${OUTPUT_DIR}/wayback_urls.txt" "${OUTPUT_DIR}/hakrawler_urls.txt" "${OUTPUT_DIR}/katana_urls.txt" 2>/dev/null
    echo

    # Stage 3: Crawl Subdomains and Analyze URLs with gf
    total_steps=9
    current_step=0
    message="Analyzing URLs for $DOMAIN"
    stdbuf -oL cat "$SUBDOMAINS_FILE" 2>/dev/null | awk '{print "https://"$0}' | hakrawler -d 2 -t 8 -u "$USER_AGENT" 2>/dev/null > "${OUTPUT_DIR}/crawl.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    stdbuf -oL katana -list "$SUBDOMAINS_FILE" -c 10 -d 3 -H "User-Agent: $USER_AGENT" 2>/dev/null >> "${OUTPUT_DIR}/crawl.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    stdbuf -oL cat "$SUBDOMAINS_FILE" 2>/dev/null | waybackurls 2>/dev/null >> "${OUTPUT_DIR}/crawl.txt" 2>/dev/null &
    pid=$!
    animate_progress "$message" $total_steps $current_step $pid
    wait $pid
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
    cat "${OUTPUT_DIR}/crawl.txt" 2>/dev/null | sort -u | grep -vE "\.(css|png|jpg|jpeg|gif|svg|woff|woff2|ttf|ico)$" > "${OUTPUT_DIR}/urls.txt" 2>/dev/null
    ((current_step++))
    draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0

    # Run gf for each pattern and collect counts
    gf_patterns=("xss" "sqli" "ssrf" "ssti" "lfi")
    declare -A gf_counts
    for pattern in "${gf_patterns[@]}"; do
        gf_counts[$pattern]=0
        stdbuf -oL cat "${OUTPUT_DIR}/urls.txt" 2>/dev/null | gf "$pattern" 2>/dev/null > "${OUTPUT_DIR}/raw_gf_${pattern}.txt" 2>/dev/null &
        pid=$!
        animate_progress "$message" $total_steps $current_step $pid
        wait $pid
        ((current_step++))
        draw_progress 10 $((current_step * 100 / total_steps)) "$message" 0
        # Remove duplicates based on parameters
        remove_duplicate_urls "${OUTPUT_DIR}/raw_gf_${pattern}.txt" "${GF_DIR}/gf_${pattern}.txt"
        if [[ -s "${GF_DIR}/gf_${pattern}.txt" ]]; then
            gf_counts[$pattern]=$(wc -l < "${GF_DIR}/gf_${pattern}.txt" 2>/dev/null || echo 0)
        else
            > "${GF_DIR}/gf_${pattern}.txt"
        fi
    done

    # Create vulnerable.txt with formatted output
    total_vulns=0
    > "$VULNERABLE_FILE"
    for pattern in "${gf_patterns[@]}"; do
        echo "${pattern}:" >> "$VULNERABLE_FILE"
        if [[ -s "${GF_DIR}/gf_${pattern}.txt" ]]; then
            cat "${GF_DIR}/gf_${pattern}.txt" >> "$VULNERABLE_FILE"
            echo "" >> "$VULNERABLE_FILE"
            ((total_vulns+=${gf_counts[$pattern]}))
        else
            echo "" >> "$VULNERABLE_FILE"
        fi
    done

    draw_progress 10 100 "$message" 0
    rm -f "${OUTPUT_DIR}/crawl.txt" "${OUTPUT_DIR}/urls.txt" "${OUTPUT_DIR}/raw_gf_*" 2>/dev/null
    echo

    # Run Nuclei if flag is set
    if [[ "$NUCLEI_FLAG" = true ]]; then
        run_nuclei_scan "$OUTPUT_DIR" "$SUBDOMAINS_FILE"
    fi

    # Display results
    echo -e "${GREEN}[*]Results for $DOMAIN:${NC}"
    echo -e "${WHITE}[*]Subdomains: $SUBDOMAINS_FILE ($subdomains_count)${NC}"
    echo -e "${WHITE}[*]JS URLs: $JS_URLS_FILE ($js_urls_count)${NC}"
    if [[ $total_vulns -gt 0 ]]; then
        echo -e "${WHITE}[*]Analysis: $VULNERABLE_FILE ($total_vulns)${NC}"
    else
        echo -e "${WHITE}  Analysis: No injection points found${NC}"
    fi
    for pattern in "${gf_patterns[@]}"; do
        echo -e "${WHITE}  ${pattern} injection point (${gf_counts[$pattern]})${NC}"
    done
    if [[ "$NUCLEI_FLAG" = true && -s "$NUCLEI_FILE" ]]; then
        nuclei_count=$(wc -l < "$NUCLEI_FILE" 2>/dev/null || echo 0)
        echo -e "${WHITE}  Nuclei results: $NUCLEI_FILE ($nuclei_count)${NC}"
    fi
    echo -e "${WHITE}  Output directory: $OUTPUT_DIR/${NC}"
    echo -e "${GREEN}Finished processing for domain: $DOMAIN${NC}"
    echo
}

# Main execution
main() {
    display_logo

    # Display targets
    echo -e "${GREEN}[*]Targets:${NC}"
    if [[ -n "$DOMAIN" ]]; then
        echo -e "${WHITE}  - $DOMAIN${NC}"
    elif [[ -n "$DOMAIN_LIST" ]]; then
        echo -e "${WHITE}  - Domains from $DOMAIN_LIST:${NC}"
        while read -r domain; do
            [[ -z "$domain" ]] && continue
            echo -e "${WHITE}    - $domain${NC}"
        done < "$DOMAIN_LIST"
    fi
    echo

    # Check dependencies and initialize
    check_dependencies
    draw_progress 10 100 "Initializing" 0
    echo

    # Process domains
    if [[ -n "$DOMAIN_LIST" ]]; then
        if [[ ! -f "$DOMAIN_LIST" ]]; then
            echo -e "${GREEN}Error: Domain list file $DOMAIN_LIST does not exist.${NC}"
            exit 1
        fi
        while read -r domain; do
            [[ -z "$domain" ]] && continue
            process_domain "$domain" "$VHOST_IP"
        done < "$DOMAIN_LIST"
    elif [[ -n "$DOMAIN" ]]; then
        process_domain "$DOMAIN" "$VHOST_IP"
    fi
}

# Parse arguments
DOMAIN=""
DOMAIN_LIST=""
VHOST_IP=""
NUCLEI_FLAG=false
while [[ $# -gt 0 ]]; do
    case $1 in
        -d) DOMAIN="$2"; shift ;;
        -l) DOMAIN_LIST="$2"; shift ;;
        -vhost) VHOST_IP="$2"; shift ;;
        -nuclei) NUCLEI_FLAG=true ;;
        -h) display_help ;;
        *) echo -e "${GREEN}Unknown option: $1${NC}"; display_help ;;
    esac
    shift
done

# Validate input
if [[ -z "$DOMAIN" && -z "$DOMAIN_LIST" ]]; then
    echo -e "${GREEN}Error: No domain or domain list specified. Use -d or -l, or -h for help.${NC}"
    display_help
fi
if [[ -n "$DOMAIN" && -n "$DOMAIN_LIST" ]]; then
    echo -e "${GREEN}Error: Cannot use both -d and -l options together. Use -h for help.${NC}"
    display_help
fi

# Set paths
WORDLIST="/home/mirage/1/tools/submaker/wordlist.txt"
RESOLVERS="/home/mirage/1/tools/submaker/resolvers.txt"
SUBDOMAINS_TXT="/home/mirage/1/tools/submaker/sublist.txt"

# Check wordlist, resolvers, and subdomains.txt
if [[ ! -f "$WORDLIST" ]]; then
    echo -e "${GREEN}Error: Wordlist not found at $WORDLIST.${NC}"
    exit 1
fi
if [[ ! -f "$RESOLVERS" ]]; then
    echo -e "${GREEN}Error: Resolvers not found at $RESOLVERS.${NC}"
    exit 1
fi
if [[ ! -f "$SUBDOMAINS_TXT" ]]; then
    echo -e "${GREEN}Error: Subdomains list not found at $SUBDOMAINS_TXT.${NC}"
    exit 1
fi

main
